{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5a136b27-808d-45db-8771-0aeb83274640",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# CS5234J: Summative Group Assessment 2\n",
    "**Goals**: In this assignment you will be practising basic tools and creating \n",
    "building blocks that will be useful in your final projects. The assignment requires\n",
    "you to solve two realistic data processing problems on the Spark platform.\n",
    "\n",
    "**Before you start:**\n",
    "* This assignment is **summative** coursework.\n",
    "* It constitutes 4% of the final course mark.\n",
    "* It consists of 2 questions.\n",
    "* The answers should be given by filling in blanks in the code cells of a copy of this \n",
    "notebook as instructed in the question descriptions and the comments in the code.\n",
    "* Do **not** create your own cells as these will not be checked!\n",
    "* Submission deadline is **7 June 2021, 10:00**\n",
    "* Submit a copy of this notebook with your answers by following the Assignment 2 \n",
    "submission link on Moodle. For example, if viewing the notebook in Jupyter, select `File->Download as->Notebook (.ipynb)` to download a copy of the notebook.\n",
    "* Please note that submitting anything rather than a copy of this notebook (e.g., a PDF file\n",
    "or a ZIP archive) will automatically result in your entire submission receiving a mark of 0. \n",
    "Likewise, any code cells that do not compile (for whatever reason, including\n",
    "accidental comments, incorrect indentation, unbalanced parentheses, etc.) will be penalized by deducting the **entire** \n",
    "quantity of marks associated with the relevant question. This is in line with the requirements \n",
    "of the departmental policy for electronic submissions: \n",
    "https://intranet.royalholloway.ac.uk/computerscience/documents/pdf/electronicsubmissionstudentversion.pdf\n",
    "* You can work in teams of **two** people. \n",
    "* If you formed a team for Assignment 1, you **must** work as part of the same team for this assignment and the final project.\n",
    "\n",
    "**Running the code**\n",
    "To run the code, we recommend using an instance of the Jupyter Notebook server integrated with \n",
    "PySpark, which can be accessed as follows:\n",
    "* Start NoMachine, and log into `linux.cim.rhul.ac.uk`\n",
    "* Open a terminal window\n",
    "* At the prompt, type `ssh -X bigdata`. Note the `X` must be capitalized.\n",
    "* Type `/home/local/ufac001/pyspark-jupyter.sh` and hit `enter` \n",
    "    to launch a Jupyter Notebook server integrated with \n",
    "PySpark. If everything works as expected, this will open up a tab in a web browser through which\n",
    "you could load and work on the notebook.\n",
    "\n",
    "As an alternative, you can also use the Databricks Community Edition cloud, but please be\n",
    "aware that their automated notebook synchronisation may not always work as expected\n",
    "potentially resulting in the loss of work. One possible workaround is to connect your notebook\n",
    "to a Git repository, and then use the provided \n",
    "commit interface to force synchronisation as necessary. If \n",
    "you would like to follow this route, and need help creating a private repository\n",
    "on GitHub (available to all RHUL students), please contact the CS Helpdesk.\n",
    "\n",
    "**Spark Restrictions**\n",
    "Your solution should use pyspark and the RDD APIs. In particular, you should *not* use\n",
    "DataFrames/DataSets or SparkSQL as part of your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "327876cb-fea4-4d7f-bb3b-fbf2f40ecda7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Question 1: Regular Expressions (5%)\n",
    "Write a regular expression pattern matching a _valid Email address_. For the purposes of this exercise, a valid Email address is any string of the form `local@domain` where \n",
    "    \n",
    "* `local` is any combination of alphanumeric (i.e., both letters and numbers) charcters in \n",
    "    either lower or upper case, dots (`.`) and the following characters \n",
    "    ``!#$%&'*+-/=?^_`{|}~``, and\n",
    "    \n",
    "* `domain` is a sequence of labels separated by a single `.` (dot) character where each label \n",
    "    is a combination of alphanumeric (i.e., both letters and numbers) characters in either lower \n",
    "    or upper case, and the rightmost label representing the top-level domain is not all numbers.\n",
    "\n",
    "For example,  all of the following strings are valid EMails: joe<span>@example.com, \n",
    "joe.doe<span>@bigdata.cs.rhul.ac.uk, joe..doe123$<span>@stratospheric, \n",
    "j0e.==.D_OE<span>@123dotcom.net, and the strings \n",
    "joe<span>@doe.xxx<span>@example.com, joe<span>@.example.com, joe.doe<span>@example.123, \n",
    "and joe.doe<span>@example.123..com are all invalid.\n",
    "\n",
    "In addition, write the following lambda expression:\n",
    "* `valid_email`: takes a string `s` as argument and returns `True` if `s` \n",
    "matches `email_regex`, and `False`, otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1e67f7aa-b614-4cf1-a01c-f6406f0daaad",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Your solution for `email_regex` is correct if the value returned by `re.compile(email_regex).fullmatch(s)` is not\n",
    "`None` for every string `s`, which is a valid Email address according to \n",
    "the definition above, and `None`, otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4d7bf1d1-a137-4cc1-a57e-27178b2d3afe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Put your pattern inside ''\n",
    "email_regex = r'^([a-zA-Z0-9\\!\\#\\$\\%\\&\\'*\\+\\-\\/\\=\\?\\^\\_\\`\\{\\|\\}\\~\\.]+)@(([a-zA-Z0-9]+\\.)*(?=.*[a-zA-Z])([a-zA-Z0-9]+))$'\n",
    "\n",
    "# Replace the right-hand side of the lambda with your code\n",
    "valid_email = lambda s: True if re.compile(email_regex).fullmatch(s) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9681f744-6f16-4a74-be7c-f6be2fbe884e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Question 1: Spark (80%) \n",
    "Write a function `proc_headers(lst)` that takes a list `lst` of Email headers, and returns a list of tuples `(E1, E2)` for _every_ Email transmission from `E1` to `E2`. Each header in `lst` is described by a tuple `(FROM, TO, CC, BCC)` where `FROM` is the Email address of the sender, and each of the `TO`, `CC`, and `BCC` is a string holding a list of comma-separated EMail addresses matching the `csv_regex` pattern from Assignment 1 Question 2 (A1-Q2).<p>\n",
    "Your code should be written as a series of the following Spark transformations:\n",
    "1. Use `sc.parallelize()` to create a base RDD from `lst`.\n",
    "2. Apply a `filter()` transformation to the base RDD created in step 1 to exclude all tuples where `FROM` is not a valid Email address. Use the `valid_email` lambda from Q1 above.\n",
    "3. Apply a `map()` transformation to the RDD produced at step 2 to convert each `(FROM, TO, CC, BCC)` tuple to  a `(FROM, RECPIENTS)` tuple where `RECIPIENTS` is a concatenation of `TO`, `CC`, and `BCC` obtained by a lambda which is a composition of two `concat_csv_strings` lambdas from A1-Q4.2.\n",
    "4. Apply a `map()` transformation to the RDD produced at step 3 to convert each `(FROM, RECPIENTS)` tuple to a `(FROM, EMAIL_SEQ)` tuple where `EMAIL_SEQ` is a sequence of EMail addresses in `RECPIENTS` extracted using the helper generator function `gen_seq_from_csv_string()` below.\n",
    "5. Apply a `flatMap()` transformation to the RDD produced at step 4 to convert each `(FROM, EMAIL_SEQ)` tuple to a sequence of tuples `(FROM, E)` for every Email `E` in `EMAIL_SEQ`. Use the `val_by_vec` lambda from A1-Q4.3.\n",
    "6. Apply a `filter()` tranformation to the result of step 5 to exclude all tuples with an invalid recipient address. Use the `valid_email` lambda from Q1 above.\n",
    "7. Apply another `filter()` transformation to the outcome of step 6 to exclude all tuples having the same sender and recipient Emails. Use the `not_self_loop` lambda from A1-Q4.4.\n",
    "8. Apply a `collect()` action to the RDD produced at step 7, and return the resulting string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f2d3a402-0857-4288-a94b-1aa13d52747b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def gen_seq_from_csv_string(s):\n",
    "    csv_regex = '([^\\s,]+),?'\n",
    "    match = re.compile(csv_regex).search(s,0)\n",
    "    while match:\n",
    "        yield match.group(1)\n",
    "        match = re.compile(csv_regex).search(s, match.end())\n",
    "    \n",
    "def proc_headers(lst):\n",
    "    '''\n",
    "    lst: a list of tuples (FROM, TO, CC, BCC) \n",
    "    representing EMail headers\n",
    "    Returns a list of tuples `(E1, E2)` for every Email transmission from `E1` to `E2`\n",
    "    using a series of Spark operations as described in the question.\n",
    "\n",
    "    Replace pass with your code. Use `sc` to reference the Spark context. \n",
    "    '''\n",
    "    # 1\n",
    "    rdd = sc.parallelize(lst)\n",
    "    # 2\n",
    "    data = rdd.filter(lambda x: valid_email(x[0]))\n",
    "    # 3\n",
    "    concat_csv_string = lambda s1, s2: f'{s1},{s2}'\n",
    "    data = data.map(lambda x: (x[0], concat_csv_string(x[1], concat_csv_string(x[2], x[3]))))\n",
    "    # 4\n",
    "    data = data.map(lambda x: (x[0], list(gen_seq_from_csv_string(x[1]))))\n",
    "    # 5\n",
    "    val_by_vec = lambda x, t: [(x, val) for val in t]\n",
    "    data = data.flatMap(lambda x: val_by_vec(x[0], x[1]))\n",
    "    # 6\n",
    "    data = data.filter(lambda x: valid_email(x[1]))\n",
    "    # 7\n",
    "    not_self_loop = lambda t: True if t[0] != t[1] else False\n",
    "    data = data.filter(lambda x: not_self_loop(x))\n",
    "    return data.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a23b8d9a-ef50-4f2f-9e9a-62e1373cf90b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You can use the following code to test your implementation of `proc_headers()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "763b6123-48f3-49e2-ac3e-2465aef3c39d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('bill.cordes@enron.com', 'mike.mcconnell@enron.com')\n",
      "('bill.cordes@enron.com', 'cathy.phillips@enron.com')\n",
      "('bill.cordes@enron.com', 'john.haggerty@enron.com')\n",
      "('bill.cordes@enron.com', 'george.mcclellan@enron.com')\n",
      "('bill.cordes@enron.com', 'tom.kearney@enron.com')\n",
      "('bill.cordes@enron.com', 'tom.kearney@enron.com')\n",
      "('bill.cordes@enron.com', 'cathy.phillips@enron.com')\n",
      "('stuart.staley@enron.com', 'mike.mcconnell@enron.com')\n",
      "('stuart.staley@enron.com', 'bill.cordes@enron.com')\n",
      "('stuart.staley@enron.com', 'tom.kearney@enron.com')\n",
      "('stuart.staley@enron.com', 'george.mcclellan@enron.com')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe output produced by the line above when executed with the model implementation\\nof proc_headers() was as follows:\\n\\n('bill.cordes@enron.com', 'mike.mcconnell@enron.com')\\n('bill.cordes@enron.com', 'cathy.phillips@enron.com')\\n('bill.cordes@enron.com', 'john.haggerty@enron.com')\\n('bill.cordes@enron.com', 'george.mcclellan@enron.com')\\n('bill.cordes@enron.com', 'tom.kearney@enron.com')\\n('bill.cordes@enron.com', 'tom.kearney@enron.com')\\n('bill.cordes@enron.com', 'cathy.phillips@enron.com')\\n('stuart.staley@enron.com', 'mike.mcconnell@enron.com')\\n('stuart.staley@enron.com', 'bill.cordes@enron.com')\\n('stuart.staley@enron.com', 'tom.kearney@enron.com')\\n('stuart.staley@enron.com', 'george.mcclellan@enron.com')\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header1 = ('bill.cordes@enron.com', \n",
    "           'mike.mcconnell@enron.com,cathy.phillips@enron.com,john.haggerty@enron.com',\n",
    "           'george.mcclellan@enron.com,tom.kearney@enron.com',\n",
    "           'tom.kearney@enron.com,cathy.phillips@enron.com'\n",
    "          )\n",
    "header2 = ('mike.mcconnell@enron..com', \n",
    "           'bill.cordes@enron.com,tom.kearney@enro@n.com,cathy.phillips@enron.com,john.haggerty@enron.com',\n",
    "           'george.mcclellan@enron.com',\n",
    "           'mike.mcconnell@enron.com'\n",
    "          )\n",
    "header3 = ('stuart.staley@enron.com',\n",
    "           'mike.mcconnell@enron.com,jeffrey.shankman@enron..com',\n",
    "           'bill.cordes@enron.com,tom.kearney@enron.com,cathy.phillips@en@ron.com',\n",
    "           'george.mcclellan@enron.com,stuart.staley@enron.com'\n",
    "          )\n",
    "print('\\n'.join(str(t) for t in proc_headers([header1, header2, header3])))\n",
    "'''\n",
    "The output produced by the line above when executed with the model implementation\n",
    "of proc_headers() was as follows:\n",
    "\n",
    "('bill.cordes@enron.com', 'mike.mcconnell@enron.com')\n",
    "('bill.cordes@enron.com', 'cathy.phillips@enron.com')\n",
    "('bill.cordes@enron.com', 'john.haggerty@enron.com')\n",
    "('bill.cordes@enron.com', 'george.mcclellan@enron.com')\n",
    "('bill.cordes@enron.com', 'tom.kearney@enron.com')\n",
    "('bill.cordes@enron.com', 'tom.kearney@enron.com')\n",
    "('bill.cordes@enron.com', 'cathy.phillips@enron.com')\n",
    "('stuart.staley@enron.com', 'mike.mcconnell@enron.com')\n",
    "('stuart.staley@enron.com', 'bill.cordes@enron.com')\n",
    "('stuart.staley@enron.com', 'tom.kearney@enron.com')\n",
    "('stuart.staley@enron.com', 'george.mcclellan@enron.com')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8804d00b-e940-45c4-a445-135908ad29cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Question 2: Spark (20%)\n",
    "Write a function `proc_headers(lst, N)` that applies further transformations to the dataset\n",
    "returned by the `proc_headers(lst)` function from Question 2 to identify `N` Email\n",
    "addresses, which are _most popular_ in terms of the number of Emails that where sent to them. <p>\n",
    "The output must be a list of `N` tuples `(n, E)` where `n` is the number of Email transmissions having `E` as their recipient address. The list must be sorted in the _descending_ lexicographical order, that is, `(n1, E1) > (n2, E2)` if and only if  either `n1 > n2` or `n1 == n2` and `E1 > E2`.<p>\n",
    "_Hint_: Use a `map`/`reduceByKey` pattern as in the word count example to pair Email addresses with their popularity counts, the `sortBy` transformation to sort them in the descending lexicographical order, and the `take()` action to extract the top-N records.\n",
    "<p>\n",
    "\n",
    "Note that calling `proc_headers()` first is only needed to prevent any errors \n",
    "in the implementation of Question 2 from propagating to the solution of this \n",
    "question as this way, we will be able to use the model implementation \n",
    "of `proc_headers()` for testing.\n",
    "A more efficient solution would avoid materializing the results\n",
    "of `proc_headers()` in the driver, and instead directly extend the processing \n",
    "steps of Question 2 with further operations. Make sure you understand why \n",
    "it is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b6ebef83-0a8d-49e4-ae66-89391b93e972",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_top_emails(lst, N):\n",
    "    '''\n",
    "    lst: a list of tuples (FROM, TO, CC, BCC) \n",
    "    representing EMail headers\n",
    "    N: a positive integer\n",
    "    Returns a list of N tuples `(n, E)` sorted in the descending lexicographical order\n",
    "    representing the top N most popular EMail destinations as described in the \n",
    "    question.\n",
    "    '''\n",
    "    rdd = sc.parallelize(proc_headers(lst))\n",
    "    # Insert your code after this line\n",
    "    data = rdd.map(lambda x: (x[1], 1)).reduceByKey(lambda x, y: x + y).map(lambda x: (x[1], x[0]))\n",
    "    data = data.sortBy(lambda x: x, ascending=False)\n",
    "    return data.take(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4e17b1b-2657-4e7c-9e16-cde69be997c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "You can use the following code to test your impementation of `get_top_emails()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a2b03e80-e6be-4f57-aba4-a5da4468b5f3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 'tom.kearney@enron.com')\n",
      "(2, 'mike.mcconnell@enron.com')\n",
      "(2, 'george.mcclellan@enron.com')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nThe output produced by the line above when executed with the model implementation\\nof get_top_emails() was as follows:\\n\\n(3, 'tom.kearney@enron.com')\\n(2, 'mike.mcconnell@enron.com')\\n(2, 'george.mcclellan@enron.com')\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\n'.join(str(t) for t in get_top_emails([header1, header2, header3], 3)))\n",
    "'''\n",
    "The output produced by the line above when executed with the model implementation\n",
    "of get_top_emails() was as follows:\n",
    "\n",
    "(3, 'tom.kearney@enron.com')\n",
    "(2, 'mike.mcconnell@enron.com')\n",
    "(2, 'george.mcclellan@enron.com')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "2021-CS5234-A2",
   "notebookOrigID": 854954857924568,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
